{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65589348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"moonshotai/kimi-k2-instruct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccaa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "class PersistentPythonREPLTool(PythonREPL):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._globals = {}\n",
    "\n",
    "    def run(self, command: str) -> str:\n",
    "        # Capture stdout\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = captured_output = StringIO()\n",
    "        \n",
    "        try:\n",
    "            # First try eval (single expression)\n",
    "            result = eval(command, self._globals)\n",
    "            output = captured_output.getvalue()\n",
    "            if output:\n",
    "                return output + str(result)\n",
    "            return str(result)\n",
    "        except SyntaxError:\n",
    "            # If it's a statement block, use exec\n",
    "            try:\n",
    "                exec(command, self._globals)\n",
    "                output = captured_output.getvalue()\n",
    "                return output if output else \"Executed successfully with no output.\"\n",
    "            except Exception as e:\n",
    "                output = captured_output.getvalue()\n",
    "                return output + repr(e) if output else repr(e)\n",
    "        except Exception as e:\n",
    "            output = captured_output.getvalue()\n",
    "            return output + repr(e) if output else repr(e)\n",
    "        finally:\n",
    "            # Restore stdout\n",
    "            sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d40413",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be\" \\\n",
    "                \" a valid python command. If you want to see the output of a value, you \" \\\n",
    "                \"should print it out with `print(...)`.\",\n",
    "    func=python_repl.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a33bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a878298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(name_or_callable=\"tavily_search\", description=\"Use Tavily to search the web for current or recent events.\")\n",
    "def tavily_search(query: str) -> str:\n",
    "    search = TavilySearch(  \n",
    "        max_results=5,\n",
    "        topic=\"general\",\n",
    "        )\n",
    "    response = search.invoke({\"query\": query})\n",
    "    # Return a summary of top result(s) â€” you could customize this\n",
    "    results = response.get(\"results\", [])\n",
    "    if not results:\n",
    "        return \"No results found.\"\n",
    "    return results[0].get(\"content\", \"No content available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83269e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hint(question: str) -> str:\n",
    "    \"\"\"Generate a helpful hint for a DSA problem without solving it.\n",
    "    input: question (str): The DSA problem to generate a hint for.\n",
    "    output: str: A helpful hint for the DSA problem.\"\"\"\n",
    "    \n",
    "    return llm.invoke(f\"Give a helpful hint for this DSA problem without solving it: {question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_cases(problem_description: str) -> str:\n",
    "    \"\"\"Use this to generate test cases for DSA problems.\n",
    "    input: problem_description - the DSA problem statement\n",
    "    output: 3 test cases without solving the problem\"\"\"\n",
    "    \n",
    "    return llm.invoke(f\"Create 3 test cases for this DSA problem without solving it: {problem_description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bug_hint_tool(code: str) -> str:\n",
    "    \"\"\"Use this to analyze code for logic issues and provide a subtle hint.\n",
    "    input: code - the code to analyze\n",
    "    output: str - a subtle hint about potential logic issues in the code.\n",
    "    \"\"\"\n",
    "\n",
    "    return llm.invoke(f\"Analyze this code for logic issues and give a subtle hint: {code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbce800",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [repl_tool, tavily_search,generate_hint, generate_test_cases, bug_hint_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage,SystemMessage,AnyMessage\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040091bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = SystemMessage(content=(\n",
    "    \"You are a Socratic DSA mentor. Your primary goal is to guide users to a solution through questions and hints, not to provide the answer directly. \"\n",
    "    \"Engage in a conversation. Ask clarifying questions to understand the user's thought process. \"\n",
    "    \"You have access to the following tools:\\n\"\n",
    "    \"- `repl_tool`: To execute python code.\\n\"\n",
    "    \"- `tavily_search`: To search the web.\\n\"\n",
    "    \"- `generate_hint`: To provide hints for a problem.\\n\"\n",
    "    \"- `generate_test_cases`: To generate test cases for a problem.\\n\"\n",
    "    \"- `bug_hint_tool`: To find bugs in code and provide hints.\\n\"\n",
    "    \"Only provide the full code solution if the user explicitly asks for it or is completely stuck after several hints. \"\n",
    "    \"Your role is to foster learning by encouraging the user to think for themselves.\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a81a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langgraph.graph import MessagesState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88063265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state:MessagesState):\n",
    "    return {\"messages\":[llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307dc1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)\n",
    "graph.add_node(\"assistant\", assistant)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "graph.add_edge(START,\"assistant\")\n",
    "graph.add_conditional_edges(\"assistant\", tools_condition)\n",
    "graph.add_edge(\"tools\", \"assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e17117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "app=graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04535308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a62486",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"123\"}}\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"\\nYou: \").strip()\n",
    "    if user_input.lower() in {\"exit\", \"quit\", \"cancel\"}:\n",
    "        print(\"Conversation ended.\")\n",
    "        break\n",
    "\n",
    "    # Wrap input as a HumanMessage\n",
    "    initial_input = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "\n",
    "    # Stream app output\n",
    "    for event in app.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "        event['messages'][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72eafed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
